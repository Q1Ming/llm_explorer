# predict.py
import os
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, PreTrainedModel, PreTrainedTokenizer
from typing import Tuple

# --- 1. é…ç½®å¸¸é‡ ---
# ä½¿ç”¨å¸¸é‡æ¥ç®¡ç†è·¯å¾„ï¼Œæ›´æ¸…æ™°ï¼Œæ˜“äºä¿®æ”¹
SAVED_MODEL_PATH = "sentiment_analyzer"

#åŠ è½½æ¨¡å‹
def load_trained_model(model_path: str) -> Tuple[PreTrainedModel, PreTrainedTokenizer]:
    """
    ä»æœ¬åœ°æ–‡ä»¶å¤¹åŠ è½½å¾®è°ƒå¥½çš„æ¨¡å‹å’Œåˆ†è¯å™¨ã€‚
    å¢åŠ äº†è·¯å¾„å­˜åœ¨æ€§æ£€æŸ¥ï¼Œä½¿å‡½æ•°æ›´å¥å£®ã€‚
    """
    if not os.path.isdir(model_path):
        # æä¾›æ›´æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯ï¼ŒæŒ‡å¯¼ç”¨æˆ·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬
        raise FileNotFoundError(
            f"æ¨¡å‹ç›®å½• '{model_path}' æœªæ‰¾åˆ°ã€‚ "
            f"è¯·å…ˆè¿è¡Œ 'main.py' æ¥è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹ã€‚"
        )

    print(f"æ­£åœ¨ä» '{model_path}' åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨...")

    # æ³¨æ„ï¼šæˆ‘ä»¬ç°åœ¨æ˜¯ä»ä¸€ä¸ªæœ¬åœ°ç›®å½•åŠ è½½ï¼Œè€Œä¸æ˜¯ä» Hugging Face Hub ä¸‹è½½
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    tokenizer = AutoTokenizer.from_pretrained(model_path)

    print("åŠ è½½å®Œæˆï¼")
    return model, tokenizer

#é¢„æµ‹æƒ…ç»ª
def predict_sentiment(text: str, model: PreTrainedModel, tokenizer: PreTrainedTokenizer):
    """
    ä½¿ç”¨åŠ è½½å¥½çš„æ¨¡å‹å¯¹å•ä¸ªæ–‡æœ¬è¿›è¡Œæƒ…æ„Ÿé¢„æµ‹ã€‚
    å°†æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡çš„æ“ä½œåœ¨åŠ è½½åæ‰§è¡Œä¸€æ¬¡å³å¯ï¼Œæ— éœ€åœ¨æ¯æ¬¡é¢„æµ‹æ—¶éƒ½æ‰§è¡Œã€‚
    """
    # ç¡®å®šè®¾å¤‡
    device = model.device

    # å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼Œå¹¶ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True).to(device)

    # è¿›è¡Œé¢„æµ‹ï¼Œä¸è®¡ç®—æ¢¯åº¦ä»¥èŠ‚çœèµ„æº
    with torch.no_grad():
        logits = model(**inputs).logits

    predicted_class_id = logits.argmax().item()

    # ä»æ¨¡å‹é…ç½®ä¸­è·å–æ ‡ç­¾åç§°ï¼Œè¿™æ¯”ç¡¬ç¼–ç æ›´å¯é 
    label = model.config.id2label.get(predicted_class_id, "UNKNOWN")

    print(f"æ–‡æœ¬: '{text}'")
    if label == "POSITIVE":
        print(">> é¢„æµ‹æƒ…æ„Ÿ: æ­£é¢ ğŸ‘")
    elif label == "NEGATIVE":
        print(">> é¢„æµ‹æƒ…æ„Ÿ: è´Ÿé¢ ğŸ‘")
    else:
        print(f">> é¢„æµ‹ç»“æœ: {label}")
    print("-" * 30)

#è¿è¡Œäº¤äº’å¼ä¼šè¯
def run_interactive_session(model: PreTrainedModel, tokenizer: PreTrainedTokenizer):
    """å¯åŠ¨ä¸€ä¸ªäº¤äº’å¼ä¼šè¯ï¼Œè®©ç”¨æˆ·å¯ä»¥è¿ç»­è¾“å…¥å¹¶è·å¾—é¢„æµ‹ã€‚"""
    # å°†æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡çš„æ“ä½œåœ¨è¿™é‡Œæ‰§è¡Œä¸€æ¬¡
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)
    print(f"æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡: {device.upper()}")

    print("\næƒ…æ„Ÿåˆ†æé¢„æµ‹å·²å°±ç»ªã€‚è¯·è¾“å…¥ä¸€å¥è¯è¿›è¡Œåˆ†æï¼ˆè¾“å…¥ 'exit' æˆ– Ctrl+C é€€å‡ºï¼‰ï¼š")

    try:
        while True:
            user_input = input("è¯·è¾“å…¥: ")
            if user_input.lower() == 'exit':
                break
            if not user_input.strip():
                continue

            predict_sentiment(user_input, model, tokenizer)
    except (KeyboardInterrupt, EOFError):
        print("\nå†è§ï¼")


if __name__ == "__main__":
    try:
        # åªéœ€åŠ è½½ä¸€æ¬¡æ¨¡å‹
        trained_model, trained_tokenizer = load_trained_model(SAVED_MODEL_PATH)
        # å¯åŠ¨äº¤äº’å¼ä¼šè¯
        run_interactive_session(trained_model, trained_tokenizer)
    except FileNotFoundError as e:
        print(f"é”™è¯¯: {e}")
    except Exception as e:
        print(f"å‘ç”Ÿäº†ä¸€ä¸ªæ„å¤–é”™è¯¯: {e}")
